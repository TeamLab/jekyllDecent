---
layout:            post
title:             "KCC2018 정보과학회 - 김진홍"
date:              2018-07-12 16:30:00 +0300
tags:              Conference
category:          Conference Review 
author:            kimjinhong
math:              false
published:         true
comments:          true
---
### KCC2018 정보과학회 후기
지난 6월 20일부터 22일까지 한국 컴퓨터 종합 학술대회를 다녀왔습니다!  
이번 학술대회는 제주도에서 개최되어 학회 참석도 하고 예쁜 제주도도 보고 올 수 있어 정말 좋은 경험이었습니다^^.
<figure>
   <img src="{{ "/media/img/KCC_conference.JPG" | absolute_url }}" />
   <figcaption>KCC 학회 외관</figcaption>
</figure> 
   
저희 연구실은 학회에 구두발표나 포스터 발표를 하진 않았지만, 관심있는 주제에 대한 발표가 본 학회에서 진행되어 참관하게 되었습니다.  
20일날 진행된 분과 워크샵 중 하나였던 인공지능 워크샵에서는 인공지능의 최신 동향과 응용 분야에 대한 다양한 내용들을 다루었는데 대부분이 의료 인공지능에 대한 이야기였습니다.(요즘 가장 핫한 분야인가봅니다.)  
저는 듣고 싶은 발표를 미리 결정한 상태여서,  
'발표장을 옮겨다니며 생각했던 발표를 들어야겠다!' 라고 계획하고 갔지만, 이동 시간이 넉넉치 않아 구두 발표세션은 연구하고 있던 `언어공학 분야`를 위주로 듣게되었습니다.  
아래는 제가 가장 집중하면서 들었던 발표에 대해 설명드리겠습니다.  


#### 한글 자연어 처리를 위한 빈도수 기반 음절 임베딩
인공 신경망 기반 단어 임베딩 모델은 단어 간 관계를 효과적으로 파악하는 장점이 있으나, 대부분 영어 데이터를 기반으로 연구가 진행되었고, 한글과 영어의 언어적 특성 차로 인해 한글 데이터에 그대로 적용하는데 어려움이 있어 본 연구를 진행하였다고 합니다.
한글 데이터의 임베딩은 영어 데이터와 다르게 단어(어절)단위로 하지 않는데, 그 이유는 한글의 어절은 여러 형태소의 순차적 결합인 경우가 많아 단어 임베딩으로는 의미를 충분히 반영하기가 힘듭니다. 따라서 단어보다 더 작은 단위의 임베딩이 필요합니다.  
대부분의 한글 임베딩은 형태소 분석, 음소, 음절단위로 이루어집니다.
> 1. 형태소 단위 : 형태소는 한글에서 의미를 가지는 가장 작은 말의 단위이다.  
> 문장을 형태소 단위로 분석하면 문장을 의미적으로 분석할 수 있다는 장점이 있지만, 비문법적인 표현(띄어쓰기, 오탈), 중의성, 속어 및 신조어에 대응하지 못하는 한계가 있다.
> 2. 음소 단위 : 음소는 말소리의 가장 작은 단위이다. 한글에서의 음소는 자음과 모음이다.  
> 음소 단위 분석은 신조어나 비문법적 표현도 효과적으로 처리할 수 있다는 장점이 있지만, 형태소 단위를 제대로 표현하는지에 대한 검증이 어려우며, 문장이 길 경우 입력이 지나치게 길어지는 문제가 발생할 수 있다.
> 3. 음절 단위 : 음절은 형대소와 음소 단위의 중간 단위로 볼 수 있다. 음절은 음소와 마찬가지로 소리의 단위이며 한글의 한 글자에 대응된다.  
> 음절 단위 분석은 비문법적 표현, 신조어 등을 처리할 수 있으며, 긴 문장 표현 시 음소보다 효과적으로 표현할 수 있다는 장점이 있으며, 여러 개의 음절을 결합하여 표현할 경우, 의미 단위인 형태소를 이해하는데 활용이 될 수 있다는 장점이 있다.

본 연구에서는 음소와 음절 단위의 임베딩을 CNN, RNN 모델을 활용하여 비교능하며 성능 지표로는 정확도를 사용하며 5-fold cross validation으로 각 모델을 검증합니다.    
실험에 사용한 데이터는 네이버 영화 140자평에 올라온 사용자들의 영화평 중 1점부터 10점까지 각각 5만개 씩 수집한 데이터를 사용합니다.  
분류 모델 검증을 위해서, 해당 평점을 두 가지 형태로 분류하여 라벨 정보로 활용합니다. 
> 1. 이진분류  
> - 긍정 : 7~ 10점  
> - 부정 : 1 ~ 4점
> 2. 다중분류  
> 1점 부터 10점까지의 점수를 2점 단위로 나누어 5개의 분류 생성

성능은 CNN, RNN 모두 음절 단위에서 성능이 좋았으며, CNN이 RNN보다 비교적 큰 성능차이를 보였습니다.  
이 발표를 들으며 비문법적인 표현, 신조어 등이 포함된 문장의 임베딩방법에 대해 생각해 볼 수 있어 좋았습니다.  
다만 형태소 분석을 통한 문장에 대한 성능 비교가 포함되어 있지 않아 아쉬웠습니다.

#### 워드임베딩을 이용한 문맥의존 철자오류 교정 기법 
이 발표에서는 워드 임베딩을 활용한 다양한 영역에서 철자오류를 교정함으로써 모델의 성능을 조금 더 향상시키는 방법에 대해 다루고 있습니다.
> 오류의 종류는 (1) 철자오류 (2) 문맥의존 철자오류가 존재하는데, 본 연구에서는 문맥의존 철자오류 교정에 대한 내용만 다룹니다.
> 1. 철자오류 : 같은 의미를 나타내는 단순한 오류 (예: 키보드 --> 키볻ㅡ)  
> 2. 문맥의존 철자오류 : 다른 의미를 나타내는 오류(예: 결제 --> 결재)  를 의미합니다.  
  
문맥의존 철자오류의 교정 실험의 절차는 먼저 올바르게 작성된 문서를 입력하고 단어에 대해 오류를 생성한 후, 오류가 생성된 문서를 교정하는 과정을 실행합니다.  
문서 교정은 1) 교정 후보 생성 2) 후보 간 확률 비교 3) 오류 교정 의 단계를 거칩니다.  
오류 후보를 생성하는 단계는 한글의 경우 키보드 근접거리 계산을 통해 생성하며, 다른 방법으로는 자주 틀리는 문서를 비교(위키피디아의 수정 내역을 보고 과거 단어와 수정본의 단어 비교)하는 방법이 있습니다.  

문서 교정은 교정 대상 단어와 윈도우 사이즈만큼의 문맥이 이루는 내적값의 합이며 이는 문맥의 확률값과 동일시 여기며, 교정 단어와의 거리가 가까울 수록 문장은 높은 값을 가지게 됩니다.
확률값이 가장 큰 값을 교정 단어로 선택합니다.

연구에서는 워드임베딩 모형으로 1) Word2Vec 2) GloVe 3) Fasttext를 사용했습니다.  
각 모형 별로 문맥의존 철자오류 교정에서의 효과는 아래와 같습니다.
1. Word2Vec  
분포가설의 단어 간 의미유사성과, 단어 동시 등장 정보를 보존한다는 점에서 단어 사이간의 연어관계를 파악할 수 있다.
2. GolVe  
말뭉치 전체의 통계 정보를 잘 반영하고자 하는 목적때문에 정확한 문맥정보가 필요로 하는 문맥의존 철자오류 교정에 좋은 효과를 주게된다.  
지정한 윈도우 내에서만 학습 및 분석이 이루어지는 Word2Vec모형과 Fasttext 모형과 달리 GolVe모형은 전체의 통계 정보를 반영하므로 단어 간의 좀 더 정확한 정보를 제공하는 효과가 있다.
3. Fasttext  
미등록 단어를 단어의 n-gram으로 구성한 형태로 보기 때문에 부분적인 n-gram을 이용하여 비슷한 단어를 추정할 수 있다.

성능은  F1 Score 기준, Word2Vec < n-gram < GloVe < Fasttext 순으로 Fasttext의 성능이 가장 좋았습니다.   
현재 저는 챗봇 프로젝트를 진행하고 있는데,  
실제로 문맥의존 철자오류 교정을 통해 모델의 성능을 향상시킬 수 있다면, 프로젝트의 사용자 입력 질문에 대해 문맥의존 철자오류 교정 단계를 실행하는 실험을 추가해보면 좋을 것 같다고 생각했습니다.  
* * *
KCC2018 학회에서 좋은 발표들이 많았는데, 좋은 발표 내용 뿐만 아니라 제가 공부하지 않은 다양한 분야에서 진행되는 연구들과 연구 추세등에 대해 알 수 있어 좋은 시간이었습니다.  
