---
layout: post
title: "게시판 및 공지사항 등을 크롤링하여 엑셀파일로 저장하기"
date: 2020-01-21 14:30:00 +0300
tags: crawling, crawling with Python
category: Crawling with Python
author: LeeMin-a
math: false
published: true
comments: true
---

# 2주차 Crawling with Python

## 게시판 크롤링을 통한 최근 공지사항들 엑셀파일로 저장하기

### 필요한 라이브러리

* BeautifulSoup, urllib, openpyxl

### 크롤링하고싶은 게시판 url 가져오고 필요한 부분 긁어오기

```
res = urlopen('https://www.gachon.ac.kr/community/opencampus/03.jsp?boardType_seq=358')
soup = BeautifulSoup(res, "html.parser")
```

```
data = soup.find_all('td', 'tl')
for item in data:
    num += 1
    excel_sheet.append([num, item.get_text()])
```

### 엑셀파일로 저장하기 위한 코드 작성

```
excel_file = openpyxl.Workbook()
excel_sheet = excel_file.active
excel_sheet.column_dimensions['B'].width = 100
```

* 마지막줄은 공지사항 제목이 위치하는 칸의 가로길이를 늘려주는 역할이다.

### 엑셀파일의 내용 가운데 정렬하기

```
cell_A1 = excel_sheet['A1']
cell_A1.alignment = openpyxl.styles.Alignment(horizontal="center")

cell_B1 = excel_sheet['B1']
cell_B1.alignment = openpyxl.styles.Alignment(horizontal="center")
```

### 엑셀파일 다른 이름으로 저장하고 종료하기

```
excel_file.save('school.xlsx')
excel_file.close()
```

### 실제 작성된 코드

```
from urllib.request import urlopen
from bs4 import BeautifulSoup
import openpyxl

excel_file = openpyxl.Workbook()
excel_sheet = excel_file.active
excel_sheet.column_dimensions['B'].width = 100

num = 0
excel_sheet.append(['번호', '제목'])
res = urlopen('https://www.gachon.ac.kr/community/opencampus/03.jsp?boardType_seq=358')
soup = BeautifulSoup(res, "html.parser")

data = soup.find_all('td', 'tl')
for item in data:
    num += 1
    excel_sheet.append([num, item.get_text()])

cell_A1 = excel_sheet['A1']
cell_A1.alignment = openpyxl.styles.Alignment(horizontal="center")

cell_B1 = excel_sheet['B1']
cell_B1.alignment = openpyxl.styles.Alignment(horizontal="center")

excel_file.save('school.xlsx')
excel_file.close()
```

### 결과

![excel](https://user-images.githubusercontent.com/59161563/72875409-8f022700-3d37-11ea-99a7-1d1acbff9dcd.PNG)
